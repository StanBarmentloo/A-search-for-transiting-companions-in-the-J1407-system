{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from alt_period_finder import alt_period_finder\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table, Column, MaskedColumn\n",
    "import butcher1 as butcher\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy import modeling\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Math\n",
    "\n",
    "import scipy.optimize as op\n",
    "import os\n",
    "import emcee\n",
    "import corner\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import emcee\n",
    "\n",
    "\n",
    "font = {'family':'normal', 'weight':'bold', 'size':36}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "\n",
    "#Get the data directory\n",
    "cwd = os.getcwd()\n",
    "data_dir = cwd.replace('Figure_6', 'Data\\\\')\n",
    "\n",
    "#ASAS data\n",
    "orgasas_data = ascii.read(data_dir + 'asas.csv')\n",
    "asas_mask = (orgasas_data['mag'] > np.mean(orgasas_data['mag'])-2*np.std(orgasas_data['mag']))*(orgasas_data['emag'] < 0.05)\n",
    "asas_data = orgasas_data[asas_mask]\n",
    "\n",
    "asas_flux = butcher.mag_to_flux(asas_data['mag'])\n",
    "asas_eflux = butcher.emag_to_eflux(asas_data['mag'], asas_data['emag'])\n",
    "\n",
    "#ASASSN data\n",
    "orgasassn_data = ascii.read(data_dir + 'asassn.csv')\n",
    "asassn_mask = (orgasassn_data['mag'] > np.mean(orgasassn_data['mag'])-2*np.std(orgasassn_data['mag']))*(orgasassn_data['emag'] < 0.05)\n",
    "asassn_data = orgasassn_data[asassn_mask]\n",
    "\n",
    "asassn_flux = butcher.mag_to_flux(asassn_data['mag'])\n",
    "asassn_eflux = butcher.emag_to_eflux(asassn_data['mag'], asassn_data['emag'])\n",
    "\n",
    "#KELT data\n",
    "orgkelt_data = ascii.read(data_dir + 'kelt.csv')\n",
    "kelt_mask = (orgkelt_data['mag'] > np.mean(orgkelt_data['mag'])-2*np.std(orgkelt_data['mag']))*(orgkelt_data['emag'] < 0.05)\n",
    "kelt_data = orgkelt_data[kelt_mask]\n",
    "\n",
    "kelt_flux = butcher.mag_to_flux(kelt_data['mag'])\n",
    "kelt_eflux = butcher.emag_to_eflux(kelt_data['mag'], kelt_data['emag'])\n",
    "\n",
    "#PROMPT data\n",
    "orgprompt_data = ascii.read(data_dir + 'prompt.csv') #time is JD-2450000\n",
    "prompt_mask = (orgprompt_data['mag'] > np.mean(orgprompt_data['mag'])-2*np.std(orgprompt_data['mag']))*(orgprompt_data['emag'] < 0.05)\n",
    "prompt_data = orgprompt_data[prompt_mask]\n",
    "\n",
    "prompt_flux = butcher.mag_to_flux(prompt_data['mag'])\n",
    "prompt_eflux = butcher.emag_to_eflux(prompt_data['mag'], prompt_data['emag'])\n",
    "\n",
    "#ROAD data\n",
    "orgroad_data = ascii.read(data_dir + 'road.csv') #time is JD-2450000\n",
    "road_mask = (orgroad_data['mag'] > np.mean(orgroad_data['mag'])-2*np.std(orgroad_data['mag']))*(orgroad_data['emag'] < 0.05)\n",
    "road_data = orgroad_data[road_mask]\n",
    "\n",
    "road_flux = butcher.mag_to_flux(road_data['mag'])\n",
    "road_eflux = butcher.emag_to_eflux(road_data['mag'], road_data['emag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(road_data['HJD']), np.max(road_data['HJD']), len(road_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "def fit_sine(time, period, comb_sigma):\n",
    "    \n",
    "    def sine(x, period, a, b, d):\n",
    "        #Creates a sine curve with parameters a, b, d but with fixed c (period)\n",
    "        return a+b*np.sin((2*np.pi/period)*(x-d))\n",
    "    \n",
    "    #Fit a sine curve with this set period\n",
    "    popt, pcov = curve_fit(sine, time, periods, p0 = [period, 3.2, 0.03, 56750], sigma=comb_sigma, absolute_sigma = True)\n",
    "    return popt, pcov\n",
    "\n",
    "def fit_sine2(time, period, fluxes, comb_sigma):\n",
    "    \n",
    "    def sine(x, period, a, b, d):\n",
    "        #Creates a sine curve with parameters a, b, d but with fixed c (period)\n",
    "        return a+b*np.sin((2*np.pi/period)*(x-d))\n",
    "    \n",
    "    #Fit a sine curve with this set period\n",
    "    popt, pcov = curve_fit(sine, time, fluxes, p0 = [period, 3.2, 0.03, 56750], sigma=comb_sigma, absolute_sigma = True)\n",
    "    return popt, pcov\n",
    "\n",
    "def sine(x, period, a, b, d):\n",
    "    #print(np.max((2*np.pi/period)*(x-d)))\n",
    "    #print(np.min((2*np.pi/period)*(x-d)))\n",
    "   \n",
    "    return a+b*np.sin(((2*np.pi/period)*(x-d))*u.radian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmb_flux = butcher.long_correct(hmb_data['HJD'], hmb_flux, hmb_eflux)\n",
    "asas_flux = butcher.long_correct(asas_data['MJD'], asas_flux, asas_eflux)\n",
    "asassn_flux = butcher.long_correct(asassn_data['MJD'], asassn_flux, asassn_eflux)\n",
    "kelt_flux = butcher.long_correct(kelt_data['HJD'], kelt_flux, kelt_eflux)\n",
    "prompt_flux = butcher.long_correct(prompt_data['HJD'], prompt_flux, prompt_eflux)\n",
    "road_flux = butcher.long_correct(road_data['HJD'], road_flux, road_eflux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binner(bins, time, flux):\n",
    "    means, errors = [], []\n",
    "    midpoints = [(bins[i] + bins[i+1])/2 for i in range(len(bins)-1)]\n",
    "    for i in range(len(bins)-1):\n",
    "        binned_mask = (time < bins[i+1])*(time > bins[i])\n",
    "        means.append(np.mean(flux[binned_mask]))\n",
    "        errors.append(np.std(flux[binned_mask])/np.sqrt(len(flux[binned_mask])))\n",
    "    return means, errors, midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "times = [asas_data['MJD'], asassn_data['MJD'], kelt_data['HJD'], prompt_data['HJD'], road_data['HJD']]\n",
    "fluxes = [asas_flux, asassn_flux, kelt_flux, prompt_flux, road_flux]\n",
    "uncertainties = [asas_eflux, asassn_eflux, kelt_eflux, prompt_eflux, road_eflux]\n",
    "names = ['ASAS', 'ASAS-SN', 'KELT', 'PROMPT', 'ROAD']\n",
    "periods=np.linspace(1.5,5, 500)\n",
    "\n",
    "#fig, ax = plt.subplots(5, 2)\n",
    "\n",
    "font = {'family':'normal', 'weight':'bold', 'size':8}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    yes = True\n",
    "    if yes:\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        time, flux, uncertainty = times[i], fluxes[i], uncertainties[i]\n",
    "        frequency, power = LombScargle(time, flux-np.mean(flux), uncertainty).autopower(minimum_frequency=1/(np.max(periods)), maximum_frequency=1/(np.min(periods)), samples_per_peak=10)\n",
    "\n",
    "        maximum_power = 1/np.max(frequency[np.where(power == np.max(power))[0]])\n",
    "\n",
    "        ax[i, 0].plot(1/frequency, power, label = names[i] + ', Maximum Period: ' + '{0:.3f}'.format(maximum_power) + ' days')\n",
    "        if i == 4:\n",
    "            ax[i, 0].set_xlabel('Periodicity of the signal (Days)')\n",
    "        ax[i, 0].set_ylabel('Power of the signal')\n",
    "        ax[i, 0].axvline(x = 0.5*maximum_power, linestyle = '--', c = 'r', label = '0.5 times Maximum Period', alpha = 0.3)\n",
    "        ax[i, 0].legend()\n",
    "\n",
    "        means, errors, midpoints = binner(np.linspace(0, maximum_power, 50), time%(maximum_power), flux)\n",
    "        ax[i, 1].errorbar(midpoints, means/np.mean(flux), errors, fmt = '.')\n",
    "\n",
    "        popt, pcov = curve_fit(sine, midpoints, means/np.mean(flux), p0 = [maximum_power, 1, 0.03, 2.1], sigma=errors, absolute_sigma = True)\n",
    "        print(np.diag(np.sqrt(pcov))[0])\n",
    "        print('amp ', popt[2])\n",
    "\n",
    "        sine_space = np.linspace(0, maximum_power*3, 500)\n",
    "\n",
    "        ax[i, 1].plot(sine_space, sine(sine_space, popt[0], popt[1], popt[2], popt[3]), label = names[i] + ', Best sine with period: '+str(popt[0])[:5] + ' days')\n",
    "        ax[i, 1].axhline(y = 1, linestyle = '--', c= 'grey', label = 'Mean')\n",
    "        ax[i, 1].set_ylim(0.95, 1.05)\n",
    "        ax[i, 1].legend()\n",
    "        if i == 4:\n",
    "            ax[i, 1].set_xlabel('Folded Period (Days)')\n",
    "        ax[i, 1].set_ylabel('Mean Flux')\n",
    "\n",
    "        print(np.min(time), np.max(time))\n",
    "    \n",
    "    \n",
    "    \n",
    "#fig = plt.gcf()\n",
    "#fig.set_size_inches(10,10)\n",
    "#plt.savefig('LombScargle_&_Sinefit.pdf')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr_hmb, p1 = butcher.short_correct(hmb_data['HJD'], hmb_flux, hmb_eflux)\n",
    "corr_asas, p2 = butcher.short_correct(asas_data['MJD'], asas_flux, asas_eflux)\n",
    "corr_asassn, p3 = butcher.short_correct(asassn_data['MJD'], asassn_flux, asassn_eflux)\n",
    "corr_kelt, p4 = butcher.short_correct(kelt_data['HJD'], kelt_flux, kelt_eflux)\n",
    "corr_prompt, p6 = butcher.short_correct(prompt_data['HJD'], prompt_flux, prompt_eflux)\n",
    "corr_road, p5 = butcher.short_correct(road_data['HJD'], road_flux, road_eflux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the uncorrected data:\n",
    "all_times = np.concatenate((np.array(asas_data['MJD']), np.array(asassn_data['MJD']), np.array(kelt_data['HJD']), np.array(prompt_data['HJD']), np.array(road_data['HJD']))) #np.array(hmb_data['HJD']),\n",
    "all_flux = np.concatenate((np.array(asas_flux), np.array(asassn_flux), np.array(kelt_flux), np.array(prompt_flux), np.array(road_flux))) #np.array(hmb_flux),\n",
    "all_eflux = np.concatenate((np.array(asas_eflux), np.array(asassn_eflux), np.array(kelt_eflux), np.array(prompt_eflux), np.array(road_eflux))) #np.array(hmb_eflux)\n",
    "\n",
    "all_flux_short = np.concatenate((np.array(corr_asas), np.array(corr_asassn), np.array(corr_kelt), np.array(corr_prompt), np.array(corr_road))) #np.array(corr_hmb),\n",
    "alt_flux_short, p555 = butcher.short_correct(all_times, all_flux, all_eflux)\n",
    "print(alt_flux_short)\n",
    "all_times_final, all_flux_final, all_flux_short_final, all_eflux_final = zip(*sorted(zip(all_times, all_flux, alt_flux_short, all_eflux)))\n",
    "\n",
    "all_times_final = np.array(all_times_final)\n",
    "all_flux_final = np.array(all_flux_final)\n",
    "all_flux_short_final = np.array(all_flux_short_final)\n",
    "all_eflux_final = np.array(all_eflux_final)\n",
    "print(all_flux_short_final)\n",
    "atf, aff, afsf, aef = np.zeros(len(all_times_final)), np.zeros(len(all_times_final)), np.zeros(len(all_times_final)), np.zeros(len(all_times_final))\n",
    "atf[:], aff[:], afsf[:], aef[:] = all_times_final, all_flux_final, all_flux_short_final, all_eflux_final\n",
    "\n",
    "print(len(atf))\n",
    "\n",
    "#from numpy import savetxt\n",
    "#savetxt('final_comb_data_S.csv', final_array, delimiter=',')\n",
    "#savetxt('final_comb_flux.csv', flux_final, delimiter=',')\n",
    "#savetxt('final_comb_eflux.csv', eflux_final, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_flux_short = np.concatenate((np.array(corr_hmb),np.array(corr_asas),np.array(corr_asassn),np.array(corr_kelt),np.array(corr_prompt),np.array(corr_road)))\n",
    "print(all_times_final, all_flux_short_final, all_eflux_final)\n",
    "#all_times = np.concatenate(all_times)\n",
    "#all_eflux = np.concatenate(all_eflux)\n",
    "plt.errorbar(all_times_final, all_flux_short_final, yerr=all_eflux_final, fmt='.', ms=3, elinewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Seperate for each data set:\n",
    "times = [asas_data['MJD'], asassn_data['MJD'], kelt_data['HJD'], prompt_data['HJD'], road_data['HJD']] #hmb_data['HJD'], \n",
    "fluxes = [asas_flux, asassn_flux, kelt_flux, prompt_flux, road_flux] #hmb_flux, \n",
    "efluxes = [asas_eflux, asassn_eflux, kelt_eflux, prompt_eflux, road_eflux] #hmb_eflux, \n",
    "\n",
    "sep_midpoints = []\n",
    "sep_periods = []\n",
    "sep_errors = []\n",
    "\n",
    "sample_sizes = [75, 75, 75, 75, 75]\n",
    "points_per_cycles = [2.5, 2.5, 2.5, 2.5, 2.5]\n",
    "\n",
    "for i in range(5):\n",
    "    alt_comb_midpoints = []\n",
    "    alt_comb_periods = []\n",
    "    alt_comb_errors = []\n",
    "    \n",
    "    midpoints, chunk_periods, errors = alt_period_finder(times[i], fluxes[i], efluxes[i], sample_size = sample_sizes[i], points_per_cycle = points_per_cycles[i])\n",
    "    for k in chunk_periods:\n",
    "        alt_comb_periods.append(k)\n",
    "    for l in midpoints:\n",
    "        alt_comb_midpoints.append(l)\n",
    "    for m in errors:\n",
    "        alt_comb_errors.append(m)\n",
    "            \n",
    "    alt_comb_midpoints = np.array(alt_comb_midpoints)\n",
    "    alt_comb_periods = np.array(alt_comb_periods)\n",
    "    alt_comb_errors = np.array(alt_comb_errors).astype(np.float)\n",
    "\n",
    "    alt_better_mask = (alt_comb_periods < 3.29) * (alt_comb_periods > 3.11) * (alt_comb_errors < 0.05)\n",
    "    \n",
    "    true = 0\n",
    "    for i in range(len(alt_better_mask)):\n",
    "        if alt_better_mask[i] == True:\n",
    "            true +=1\n",
    "    print(true, len(alt_better_mask))\n",
    "    sep_midpoints.append(alt_comb_midpoints[alt_better_mask])\n",
    "    sep_periods.append(alt_comb_periods[alt_better_mask])\n",
    "    sep_errors.append(alt_comb_errors[alt_better_mask])\n",
    "    \n",
    "combined_midpoints = np.concatenate(sep_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sep_midpoints)\n",
    "\n",
    "names = ['ASAS', 'ASASSN', 'KELT', 'PROMPT', 'ROAD'] #'AAVSO', \n",
    "for i in range(5):\n",
    "    if len(sep_midpoints[i]) != 0:#ASASSN does not yield any periods\n",
    "        plt.errorbar(sep_midpoints[i], sep_periods[i], sep_errors[i], fmt='.')\n",
    "    \n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(18, 12)\n",
    "plt.xlim(np.min(combined_midpoints)-200, np.max(combined_midpoints) + 200)\n",
    "#plt.ylim(3.1, 3.3)\n",
    "#plt.savefig(\"75_days_3ppc_33result.pdf\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(len(combined_midpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ASAS', 'ASASSN', 'KELT', 'PROMPT', 'ROAD'] #'AAVSO', \n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, tight_layout=True)\n",
    "\n",
    "for i in range(5):\n",
    "    if sep_midpoints[i] != []: #ASASSN does not yield any periods\n",
    "        axs[1].errorbar(sep_midpoints[i], sep_periods[i], yerr=sep_errors[i], fmt='.', ms=5, elinewidth=0.5, label=names[i])\n",
    "\n",
    "combined_midpoints = np.concatenate(sep_midpoints)\n",
    "combined_periods = np.concatenate(sep_periods)\n",
    "combined_errors = np.concatenate(sep_errors)\n",
    "\n",
    "combined_masky = (combined_errors <  0.02) * (combined_midpoints > 57000)\n",
    "\n",
    "average_period = np.average(sep_periods[-1], weights=sep_errors[-1])\n",
    "print(average_period)\n",
    "popt=fit_sine2(combined_midpoints[combined_masky], average_period, combined_periods[combined_masky], combined_errors[combined_masky])\n",
    "\n",
    "\n",
    "axs[0].errorbar(all_times_final, all_flux_short_final, yerr=all_eflux_final, fmt='.', ms=3, elinewidth=0.5)\n",
    "#axs[1].plot(np.linspace(np.min(combined_midpoints), np.max(combined_midpoints), 1000), sine(np.linspace(np.min(combined_midpoints), np.max(combined_midpoints), 1000), *popt), color='red', alpha=0.6, label='fit ['+str(popt[0])[:7]+\"   \"+str(popt[1])[:6]+\"   \"+str(popt[2])[:6]+']')\n",
    "print(*popt)\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(24, 18)\n",
    "axs[1].axhline(average_period, color='black', alpha=0.5, ls='--')\n",
    "axs[1].set_xlabel('Julian date -2400000 (days)')\n",
    "axs[1].set_ylabel('Rotation period (days)')\n",
    "axs[0].set_ylabel('Normalised Flux')\n",
    "#plt.xlim(55000, 59000)\n",
    "plt.legend()\n",
    "#plt.savefig('lightcurve_and_variability.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharex=True, tight_layout=True)\n",
    "\n",
    "mask6 = combined_periods < 3.17\n",
    "bad_fit_mask = mask6#mask5 + mask1 + mask2 + mask3 \n",
    "good_fit_mask = np.invert(bad_fit_mask)\n",
    "names = ['ASAS', 'ASASSN', 'KELT', 'PROMPT', 'ROAD'] #'AAVSO', \n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    if sep_midpoints[i] != []: #ASASSN does not yield any periods\n",
    "        axs.errorbar(sep_midpoints[i], sep_periods[i], yerr=sep_errors[i], fmt='.', ms=3, elinewidth=0.5, label=names[i])\n",
    "axs.axhline(average_period, color='black', alpha=0.3, ls='--')\n",
    "axs.legend(fontsize=14, loc='upper left')\n",
    "\n",
    "popt, pcov =fit_sine2(combined_midpoints[good_fit_mask], average_period, combined_periods[good_fit_mask], combined_errors[good_fit_mask])#combined_errors[good_fit_mask])\n",
    "axs.plot(np.linspace(np.min(combined_midpoints[good_fit_mask]), np.max(combined_midpoints[good_fit_mask]), 1000), sine(np.linspace(np.min(combined_midpoints[good_fit_mask]), np.max(combined_midpoints[good_fit_mask]), 1000), *popt), color='red', zorder=20, alpha=0.6, label='fit ['+str(popt[0])[:7]+\"   \"+str(popt[1])[:6]+\"   \"+str(popt[2])[:6]+']')\n",
    "#axs[1].errorbar(combined_midpoints[good_fit_mask], combined_periods[good_fit_mask], yerr=combined_errors[good_fit_mask], fmt='.', ms=3, elinewidth=0.5, label='Combined data used for fit')\n",
    "axs.errorbar(combined_midpoints[bad_fit_mask], combined_periods[bad_fit_mask], yerr=combined_errors[bad_fit_mask], fmt='.', ms=2, elinewidth=0.5, color='black', alpha=1, label='Omitted data with periodic irregularities')\n",
    "axs.axhline(average_period, color='black', alpha=0.3, ls='--')\n",
    "\n",
    "print(*popt)\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(18, 9)\n",
    "axs.set_xlabel('MJD (days)')\n",
    "axs.set_ylabel('Rotation period (days)')\n",
    "axs.set_ylabel('Rotation period (days)')\n",
    "#axs[0].set_ylabel('Normalised flux')\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "plt.suptitle('Long term variability of J1407')\n",
    "#plt.savefig('75_days_3ppc_33result_fit_with_prev_mask.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = combined_midpoints[good_fit_mask]\n",
    "y_data = combined_periods[good_fit_mask]\n",
    "y_err = combined_errors[good_fit_mask]\n",
    "\n",
    "time_space = np.linspace(np.min(x_data)-100, np.max(x_data)+100, 5000)\n",
    "\n",
    "x_data, y_data, y_err = zip(*sorted(zip(x_data, y_data, y_err)))\n",
    " \n",
    "###par =    [2350,         55700,       3.2,      0.015] #Guess based on previous results\n",
    "par =    [1950,         56800,       3.2,      0.018] #Guess based on previous results\n",
    "\n",
    "labels = [\"$P_{act}$\", \"$t_0$\", \"$P_{mean}$\", \"$a$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_model(t, P, t0, mean, a):\n",
    "    P_activity = mean + a * np.sin(2*np.pi * (t-t0)/P) \n",
    "    return P_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pact_model = activity_model(time_space, 2350, 55700, 3.20, 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnlike(theta, t, f, ferr):\n",
    "    ''' theta holds the free parameters of the model, t,f, ferr are the noisy observed measurements'''\n",
    "    P, t0, mean, a = theta\n",
    "\n",
    "    # calculate the model with the values in theta, and the data in (t,f,ferr)\n",
    "    model = activity_model(t, P, t0, mean, a)\n",
    "    \n",
    "    # calculate the chi squared for each epoch\n",
    "    chi2 = np.power((f-model)/ferr,2.)\n",
    "    \n",
    "    # add up all the chi squareds, and the -0.5 is for emcee\n",
    "    #print(-0.5*(np.sum(chi2)))\n",
    "    return -0.5*(np.sum(chi2))\n",
    "\n",
    "\n",
    "# this nll function is for the minimise function, which wants a MINIMISE a value, not maximise it.\n",
    "nll = lambda *args: -lnlike(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = op.minimize(nll, par, method='nelder-mead', args=(x_data,y_data,y_err),\n",
    "                     options={'maxiter':10000,'xtol': 1e-8, 'disp': True})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior - here we choose whether to restrict the fitting paramaters\n",
    "def lnprior(theta):\n",
    "    P, t0, mean, a = theta\n",
    "    if 500 < P < 3000 and 3.10 < mean < 3.3:\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnprob(theta, t, f, ferr):\n",
    "    lp = lnprior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike(theta, t, f, ferr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim, nwalkers = 4, 100\n",
    "\n",
    "# we can add the parameters found in the LWFIT above:\n",
    "par = result.x\n",
    "\n",
    "pos = [par + 1e-4*np.random.randn(ndim) for i in range(nwalkers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=(x_data,y_data,y_err), threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "pos, prob, state = sampler.run_mcmc(pos, 15000)\n",
    "#end = time.time()\n",
    "#print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sampler.get_autocorr_time(c=1))\n",
    "print(sampler.acceptance_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn = 600\n",
    "print(sampler.chain.shape)\n",
    "samples = sampler.chain[:, burn:, :].reshape((-1, ndim))\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(samples[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt = \"\\mathrm{{{3}}} = {0:.4f}_{{-{1:.4f}}}^{{{2:.4f}}}\"\n",
    "    txt = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "    display(Math(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.randint(len(samples), size=100)\n",
    "\n",
    "font = {'family':'normal', 'weight':'normal', 'size':38}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "fig1, f1a = plt.subplots(ncols=1,nrows=1, figsize=(10,6), constrained_layout=True)\n",
    "colours = ['red', 'black', 'red', 'blue', 'blue', 'yellow']\n",
    "odd_mask = combined_midpoints < 3.17\n",
    "\n",
    "for i in range(5): #[ 2, 4]:\n",
    "    if i > 1:\n",
    "        f1a.errorbar(sep_midpoints[i],sep_periods[i],yerr=sep_errors[i],fmt='o',capsize=0 ,mew=3, elinewidth=1,ms=5, label=names[i])\n",
    "\n",
    "\n",
    "a = np.percentile(samples[:, 0], [50])[0]\n",
    "b = np.percentile(samples[:, 1], [50])[0]\n",
    "c = np.percentile(samples[:, 2], [50])[0]\n",
    "d = np.percentile(samples[:, 3], [50])[0]\n",
    "\n",
    "a_copy = np.copy(a)\n",
    "b_copy = np.copy(b)\n",
    "c_copy = np.copy(c)\n",
    "d_copy = np.copy(d)\n",
    "\n",
    "    \n",
    "Pact_model = activity_model(time_space, a, b, c, d)    \n",
    "    \n",
    "f1a.plot(time_space,Pact_model,'r-', c= 'brown', linewidth=3,zorder=10, label='Best fit')#fit ['+str(int(a+1))[:4]+\"   \"+str(c)[:5]+\"   \"+str(d)[:5]+']')\n",
    "f1a.axhline(y= np.percentile(samples[:, 2], [50]), linestyle = '--', c='black')\n",
    "#f1a.errorbar(combined_midpoints[bad_fit_mask], combined_periods[bad_fit_mask], yerr=combined_errors[bad_fit_mask], c = 'black', fmt='o', capsize=0 ,mew=3, elinewidth=1,ms=3, label='Omitted data')\n",
    "\n",
    "f1a.set_xlabel('MJD (Days)')\n",
    "f1a.set_ylabel('Measured rotational period (Days)')\n",
    "for ind in inds:\n",
    "    onesample = samples[ind]\n",
    "    P, t0, mean, a = onesample\n",
    "\n",
    "    # calculate the model with the values in theta, and the data in (t,f,ferr)\n",
    "    onemodel = activity_model(time_space, P, t0, mean, a) \n",
    "    plt.plot(time_space, onemodel, \"C1\", alpha=0.1)\n",
    "    if ind == inds[-1]:\n",
    "        plt.plot(time_space, onemodel, \"C1\", alpha=0.2, label = 'Model fits')\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(18, 12)\n",
    "    \n",
    "plt.legend(fontsize = 24)\n",
    "\n",
    "#f1a.plot(time_space, linear(time_space, *lin_popt), lw = 3)\n",
    "\n",
    "#fig1.savefig('Activity_cycle_30_05.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIC Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(n, k, data, model, err):\n",
    "    wlsq = np.sum((data-model)**2/err**2)\n",
    "    return n*np.log(wlsq/n)+k*np.log(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, a, b):\n",
    "    return a*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_times, f_means, f_errs = np.concatenate(sep_midpoints), np.concatenate(sep_periods), np.concatenate(sep_errors)\n",
    "\n",
    "lin_popt, pcov = curve_fit(linear, f_times, f_means, p0 = [0, 3.21], sigma=f_errs, absolute_sigma = True)\n",
    "sine_popt = [a_copy, b_copy, c_copy, d_copy]\n",
    "\n",
    "n = len(f_times)\n",
    "k_sine = 4\n",
    "k_lin = 2\n",
    "\n",
    "sin_bic = bic(n, k_sine, f_means, activity_model(f_times, *sine_popt), f_errs)\n",
    "lin_bic = bic(n, k_lin, f_means, linear(f_times, *lin_popt), f_errs)\n",
    "\n",
    "print(\"the sinbic is: \", '{0:.2f}'.format(sin_bic))\n",
    "print(\"the linbic is: \", '{0:.2f}'.format(lin_bic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import butcher1 as butcher\n",
    "import bro\n",
    "import os\n",
    "\n",
    "from numpy import savetxt\n",
    "from astropy.io import ascii\n",
    "from astropy.time import Time\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.stats import median_absolute_deviation\n",
    "\n",
    "from collections import deque\n",
    "from bisect import insort, bisect_left\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binner(bins, time, flux, eflux):\n",
    "    means, errors, midpoints = [], [], []\n",
    "    for i in range(len(bins)-1):\n",
    "        binned_mask = (time < bins[i+1])*(time > bins[i])\n",
    "        if np.all(binned_mask == False):\n",
    "            pass\n",
    "        else:\n",
    "            midpoints.append((bins[i] + bins[i+1])/2)\n",
    "            means.append(np.average(flux[binned_mask], weights = 1/eflux[binned_mask]**2))\n",
    "            errors.append(np.std(flux[binned_mask])/np.sqrt(len(flux[binned_mask])))\n",
    "    return means, errors, midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a0,a1,a2,a3,a4 that is the best fit to the plot above\n",
    "\n",
    "def ringaling(phi,*c):\n",
    "    # c is a numpy array containing an odd number of coeffieicnts\n",
    "    # so that c[0] + c[1]*np.sin(phi) + c[2]*np.cos(phi) + c[3]*np.sin(2*phi) + c[4]*np.cos(2*phi) + .....\n",
    "    #if (c.size%2 == 0):\n",
    "    #    print('whoa! we need an odd number of coefficients in c')\n",
    "    #    return 1\n",
    "    c = np.array(c)\n",
    "    npairs = (c.size-1)/2\n",
    "    result = 0\n",
    "    for i in np.arange(npairs):\n",
    "        a_sin = c[((i*2)+1).astype(int)]\n",
    "        a_cos = c[((i*2)+2).astype(int)]\n",
    "        result = result + a_sin*np.sin(phi*(i+1)) + a_cos*np.cos(phi*(i+1))\n",
    "    return result+c[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "\n",
    "#Get the data directory\n",
    "cwd = os.getcwd()\n",
    "data_dir = cwd.replace('Figure_2', 'Data\\\\')\n",
    "\n",
    "#ASAS data\n",
    "orgasas_data = ascii.read(data_dir + 'asas.csv')\n",
    "asas_mask = (orgasas_data['emag'] < 0.05)\n",
    "asas_data = orgasas_data[asas_mask]\n",
    "\n",
    "asas_flux = butcher.mag_to_flux(asas_data['mag'])\n",
    "asas_eflux = butcher.emag_to_eflux(asas_data['mag'], asas_data['emag'])\n",
    "\n",
    "#ASASSN data\n",
    "orgasassn_data = ascii.read(data_dir + 'asassn.csv')\n",
    "asassn_mask = (orgasassn_data['emag'] < 0.05)\n",
    "asassn_data = orgasassn_data[asassn_mask]\n",
    "\n",
    "asassn_flux = butcher.mag_to_flux(asassn_data['mag'])\n",
    "asassn_eflux = butcher.emag_to_eflux(asassn_data['mag'], asassn_data['emag'])\n",
    "\n",
    "#KELT data\n",
    "orgkelt_data = ascii.read(data_dir + 'kelt.csv')\n",
    "kelt_mask = (orgkelt_data['emag'] < 0.05)\n",
    "kelt_data = orgkelt_data[kelt_mask]\n",
    "\n",
    "kelt_flux = butcher.mag_to_flux(kelt_data['mag'])\n",
    "kelt_eflux = butcher.emag_to_eflux(kelt_data['mag'], kelt_data['emag'])\n",
    "\n",
    "#PROMPT data\n",
    "orgprompt_data = ascii.read(data_dir + 'prompt.csv') #time is JD-2450000\n",
    "prompt_mask = (orgprompt_data['emag'] < 0.05)\n",
    "prompt_data = orgprompt_data[prompt_mask]\n",
    "\n",
    "prompt_flux = butcher.mag_to_flux(prompt_data['mag'])\n",
    "prompt_eflux = butcher.emag_to_eflux(prompt_data['mag'], prompt_data['emag'])\n",
    "\n",
    "#ROAD data\n",
    "orgroad_data = ascii.read(data_dir + 'road.csv') #time is JD-2450000\n",
    "road_mask = (orgroad_data['emag'] < 0.05)\n",
    "road_data = orgroad_data[road_mask]\n",
    "\n",
    "road_flux = butcher.mag_to_flux(road_data['mag'])\n",
    "road_eflux = butcher.emag_to_eflux(road_data['mag'], road_data['emag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asas_flux = butcher.long_correct(asas_data['MJD'], asas_flux, asas_eflux)\n",
    "asassn_flux = butcher.long_correct(asassn_data['MJD'], asassn_flux, asassn_eflux)\n",
    "kelt_flux = butcher.long_correct(kelt_data['HJD'], kelt_flux, kelt_eflux)\n",
    "prompt_flux = butcher.long_correct(prompt_data['HJD'], prompt_flux, prompt_eflux)\n",
    "road_flux = butcher.long_correct(road_data['HJD'], road_flux, road_eflux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data after long correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times = [asas_data['MJD'], asassn_data['MJD'], kelt_data['HJD'], prompt_data['HJD'], road_data['HJD']]\n",
    "fluxes = [asas_flux, asassn_flux, kelt_flux, prompt_flux, road_flux]\n",
    "uncertainties = [asas_eflux, asassn_eflux, kelt_eflux, prompt_eflux, road_eflux]\n",
    "names = ['ASAS', 'ASAS-SN', 'KELT', 'PROMPT', 'ROAD']\n",
    "\n",
    "fig, ax = plt.subplots(5, sharey= True)\n",
    "\n",
    "for i in range(5):\n",
    "    time, flux, eflux = times[i], fluxes[i], uncertainties[i]\n",
    "    \n",
    "    \n",
    "\n",
    "    ax[i].errorbar(time, flux, eflux, fmt='.', markersize= 3, elinewidth=0.5)\n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(12, 20)\n",
    "    ax[i].set_title(\"Uncorrected \" +str(names[i]))\n",
    "    #ax[i].set_ylim(0.86, 1.08)\n",
    "    print(\"Scatter is\", np.std(flux))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    time, flux, eflux = times[i], fluxes[i], uncertainties[i]\n",
    "    \n",
    "    frequencies = 1/np.linspace(2, 10, 3000)\n",
    "    power = LombScargle(time, flux-np.mean(flux), dy = eflux).power(frequencies)\n",
    "    max_period = 1/frequencies[list(power).index(np.max(power))]\n",
    "    \n",
    "    means, errors, midpoints = binner(np.linspace(0, max_period, int(2*len(time)**(1/3.))), time%max_period, flux, eflux)\n",
    "    \n",
    "    popt, pcov = curve_fit(ringaling, np.array(midpoints)*2*np.pi/(max_period), means, sigma = errors, absolute_sigma = True, p0 = [1,0,0], maxfev = 5000)\n",
    "    phi = np.arange(200)*2*np.pi / 200\n",
    "    \n",
    "    plt.errorbar(midpoints, means, errors, ms = 3, fmt = '.')\n",
    "    plt.plot(phi*max_period/(2*np.pi), ringaling(phi, *popt))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"The max is at: \", '{0:.3f}'.format(np.max(ringaling(phi, *popt))))\n",
    "    print(\"The min is at: \", '{0:.3f}'.format(np.min(ringaling(phi, *popt))))\n",
    "    print(\"The amp is at: \", '{0:.3f}'.format(np.max(ringaling(phi, *popt))-np.min(ringaling(phi, *popt))))\n",
    "    print(np.sqrt(np.diag(pcov)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Full periodogram\n",
    "names = ['ASAS', 'ASASSN', 'KELT', 'PROMPT', 'ROAD']\n",
    "corr_fluxes_1, corr_fluxes_2 = [], []\n",
    "\n",
    "org_powers, powers2 = [], []\n",
    "for j in range(5):\n",
    "    time, flux, eflux = times[j], fluxes[j], uncertainties[j]\n",
    "\n",
    "    road_corrflux, periods, road_freq1, road_power1 = bro.short_correct(time, flux, eflux, min_chunk_size = 10)\n",
    "\n",
    "    #Get the uncorrected lombscargle\n",
    "    frequencies = 1/np.linspace(2, 10, 3000)\n",
    "    org_power = LombScargle(time, flux-np.mean(flux), dy = eflux).power(frequencies)\n",
    "    org_max_period = 1/frequencies[list(org_power).index(np.max(org_power))]\n",
    "    #print(\"The highest power period is \", '{0:.3f}'.format(org_max_period), ' days.')\n",
    "\n",
    "    #Get the butcher corrected lombscargle\n",
    "    butcher_flux, butcher_periods = butcher.short_correct(time, flux, eflux)\n",
    "    frequencies = 1/np.linspace(2, 10, 3000)\n",
    "    butcher_power = LombScargle(time, butcher_flux-np.mean(butcher_flux), dy = eflux).power(frequencies)\n",
    "    butcher_max_period = 1/frequencies[list(butcher_power).index(np.max(butcher_power))]\n",
    "    #print(\"The highest power period is \", '{0:.3f}'.format(butcher_max_period), ' days.')\n",
    "    \n",
    "    #Get the bro corrected lombscargle\n",
    "    frequencies = 1/np.linspace(2, 10, 3000)\n",
    "    power = LombScargle(time, road_corrflux-np.mean(road_corrflux), dy = eflux).power(frequencies)\n",
    "    max_period = 1/frequencies[list(power).index(np.max(power))]\n",
    "    #print(\"The highest power period is \", '{0:.3f}'.format(max_period), ' days.')\n",
    "    \n",
    "    road_corrflux2, periods2, road_freq1, road_power1 = bro.short_correct(time, road_corrflux, eflux, min_chunk_size = 10)\n",
    "    frequencies = 1/np.linspace(2, 10, 3000)\n",
    "    power2 = LombScargle(time, road_corrflux2-np.mean(road_corrflux2), dy = eflux).power(frequencies)\n",
    "    max_period = 1/frequencies[list(power2).index(np.max(power2))]\n",
    "    \n",
    "    org_powers.append(org_power)\n",
    "    powers2.append(power2)\n",
    "    \n",
    "    \n",
    "    #plt.plot(1/frequencies, power2-power)\n",
    "    #fig = plt.gcf()\n",
    "    #fig.set_size_inches(12,9)\n",
    "    #plt.show()\n",
    "    \n",
    "    corr_fluxes_1.append(road_corrflux)\n",
    "    corr_fluxes_2.append(road_corrflux2)\n",
    "    \n",
    "    print(periods)\n",
    "    print(periods2)\n",
    "    print(\"The scatter is now: \", np.std(road_corrflux))\n",
    "    print(\"The scatter is now: \", np.std(road_corrflux2))\n",
    "#0.04687787284474136\n",
    "#0.021\n",
    "#0.028\n",
    "#0.069\n",
    "#0.023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(5)\n",
    "for i in range(5):\n",
    "    ax[i].plot(1/frequencies, org_powers[i], alpha = 0.7, c='grey', label = 'Pre-Correction ' + names[i])\n",
    "    #ax.plot(1/frequencies, butcher_power, alpha = 0.7, c = 'orange', label = 'Butcher-Correction')\n",
    "    ax[i].plot(1/frequencies, powers2[i], alpha = 0.7,label = 'Post-Correction ' + names[i])\n",
    "    ax[i].legend(fontsize = 18)\n",
    "\n",
    "fig.text(0.35, 0.09, 'Signal Period (Days)', fontsize = 24)\n",
    "fig.text(0.02, 0.35, 'Signal Power (Arbitrary Units)', rotation = 90, fontsize = 24)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12,20)\n",
    "#plt.savefig('Removing_Dominant_Cycle.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing 2+ sigma outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_before = 0\n",
    "for i in range(5):\n",
    "    len_before += len(times[i])\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    #print(len(corr_fluxes_2[i]))\n",
    "    #print(np.min(times[i]), np.max(times[i]))\n",
    "    flux_1, flux_2 = corr_fluxes_1[i], corr_fluxes_2[i]\n",
    "    low_1, high_1 = np.percentile(flux_1,[5, 95]) \n",
    "    low_2, high_2 = np.percentile(flux_2,[5, 95])\n",
    "    print(low_1, high_1)\n",
    "    print(low_2, high_2)\n",
    "    mask1 = (flux_1 < high_1)*(flux_1 > low_1)\n",
    "    mask2 = (flux_2 < high_2)*(flux_2 > low_2)\n",
    "    \n",
    "    corr_fluxes_1[i], corr_fluxes_2[i] = flux_1[mask1], flux_2[mask2]\n",
    "    times[i], uncertainties[i] = times[i][mask2], uncertainties[i][mask2]\n",
    "    \n",
    "len_after = 0\n",
    "for i in range(5):\n",
    "    len_after += len(times[i])\n",
    "print(\"We removed: \", '{0:.2f}'.format((len_before-len_after)*100/len_before), ' % of the data')\n",
    "\n",
    "all_corflux = np.concatenate( (np.array(corr_fluxes_2[0]+1), np.array(corr_fluxes_2[1]+1), np.array(corr_fluxes_2[2]+1), np.array(corr_fluxes_2[3]+1),  np.array(corr_fluxes_2[4]+1)))\n",
    "print(np.std(all_corflux))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sticking the different sets together\n",
    "all_times =  np.concatenate((np.array(times[0]), np.array(times[1]), np.array(times[2]), np.array(times[3]), np.array(times[4])))\n",
    "all_corflux = np.concatenate( (np.array(corr_fluxes_2[0]+1), np.array(corr_fluxes_2[1]+1), np.array(corr_fluxes_2[2]+1), np.array(corr_fluxes_2[3]+1),  np.array(corr_fluxes_2[4]+1)))\n",
    "all_eflux =  np.concatenate((np.array(uncertainties[0]), np.array(uncertainties[1]), np.array(uncertainties[2]), np.array(uncertainties[3]), np.array(uncertainties[4])))\n",
    "\n",
    "#np.concatenate((np.array(times[2]), np.array(times[4])))\n",
    "#np.concatenate((np.array(corr_fluxes_2[2]), np.array(corr_fluxes_2[4])))\n",
    "#np.concatenate((np.array(uncertainties[2]), np.array(uncertainties[4])))\n",
    "\n",
    "\n",
    "\n",
    "print(len(all_times), len(all_corflux), len(all_eflux))\n",
    "\n",
    "all_times_final, all_corflux_final, all_eflux_final = zip(*sorted(zip(all_times, all_corflux, all_eflux))) #Sorting the data timewise\n",
    "\n",
    "print(len(all_times_final), len(all_corflux_final))\n",
    "\n",
    "print(np.std(all_corflux))\n",
    "\n",
    "karpa = np.zeros((len(all_times_final), 3))\n",
    "karpa[:, 0] = all_times_final\n",
    "karpa[:, 1] = all_corflux_final\n",
    "karpa[:, 2] = all_eflux_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark-palette')\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "for i in range(5):\n",
    "    plt.errorbar(times[i], corr_fluxes_2[i]+1, uncertainties[i], fmt='.', ms=2, elinewidth = 0.2, alpha = 0.2, label = names[i])\n",
    "    \n",
    "plt.xlabel('MJD (days)')\n",
    "plt.ylabel('Normalised flux')\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(18, 10)\n",
    "plt.axhline(y = 1.0, linestyle = '--', c='black')\n",
    "plt.legend()\n",
    "#plt.savefig(\"KARPA_Lightcurve.pdf\")\n",
    "plt.show()    \n",
    "    \n",
    "plt.errorbar(karpa[:, 0], karpa[:, 1], yerr=karpa[:, 2], fmt='.', ms=3, elinewidth = 0.3, alpha = 0.3)\n",
    "plt.xlabel('MJD (days)')\n",
    "plt.ylabel('Normalised flux')\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(18, 10)\n",
    "plt.axhline(y = 1.0, linestyle = '--', c='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "colours = ['blue', 'blue', 'orange', 'green', 'green']\n",
    "\n",
    "fig, ax = plt.subplots(5)\n",
    "for i in range(5):\n",
    "    ax[i].errorbar(times[i], corr_fluxes_2[i]+1, uncertainties[i], fmt='.', ms=2, elinewidth = 0.5, label = names[i], color=colours[i])\n",
    "    ax[i].legend(fontsize = 18)\n",
    "    ax[i].axhline(y = 1.0, linestyle = '--', c='black')\n",
    "    ax[i].set_xlim(51500, 59500)\n",
    "    ax[i].set_ylim(0.85, 1.15)\n",
    "    if i != 4:\n",
    "        plt.setp(ax[i].get_xticklabels(), visible=False)\n",
    "    \n",
    "ax[2].set_ylabel('Normalised flux', fontsize=28)\n",
    "ax[4].set_xlabel('MJD (Days)', fontsize=28)\n",
    "    \n",
    "#fig.text(0.35, 0.09, 'MJD (days)', fontsize = 24)\n",
    "#fig.text(0.02, 0.35, 'Normalised flux', rotation = 90, fontsize = 24)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20,14)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('KARPA_lightcurve.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(karpa[:, 1]))\n",
    "per = 8.025650930249851\n",
    "\n",
    "means, errors, midpoints = binner(np.linspace(0, per, 271), karpa[:, 0]%per, karpa[:, 1], karpa[:, 2])\n",
    "print(np.mean(means))\n",
    "plt.errorbar(midpoints, means, errors, fmt = '.')\n",
    "plt.axhline(y = 1, linestyle = '--', c='grey', alpha = 0.4)\n",
    "plt.xlim(0, 3)\n",
    "plt.show()\n",
    "\n",
    "#plt.errorbar(karpa[:, 0]%per, karpa[:, 1], karpa[:, 2], fmt = '.', ms= 0.5, elinewidth = 0.1)\n",
    "#plt.axhline(y = 1, linestyle = '--', c='grey', alpha = 0.4)\n",
    "#fig = plt.gcf()\n",
    "#fig.set_size_inches(12, 9)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karpa[: , 1] /= np.mean(karpa[:, 1])\n",
    "#np.savetxt(\"Final_Combined_Data.csv\", karpa, header = 'Time,Flux,Eflux') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
